Using langChain groq model

make extended terminal with python

the agent should have system prompt generate
  - title: (20character without spaces) on what this bash script do
  - description: short description about the bash script maximum (50 word)
  - bashscript: bash script from the user prompt

state 1:
if the command correctly executed without errors then don't do anything

state 2:
trigger: the command wrongly executed, have error, or the user started the commmand with "?"
action:
  - the agent should understand what the user wants and create a bash scripts
  - show bash scripts to the user in gray color
  - and a question "Should I execute? [Shift-Enter]" in a red color
  - if the user accept, chmod+x and excute
more actions:
  - the bash script should be saved at /home/$USER/.llmterminal/{title}_{datatime}.sh (commenting inside this the title / description / and the user prompt)
  - and when this state happens you should save the user question with the bash script with a short description of this script do in a file

the user will save the API_KEYS in a .env file , also here the user will decide which model to use and if it will user groq or ollama

-------------------------
Using langChain groq and ollama

 the agent should have system prompt generate  ex_bash_script
   - # title: (20character without spaces) on what this bash script do
   - # description: short description about the bash script maximum (50 word)
   - bashscript: bash script from the user prompt

 make python program that operate in the background of my terminal
 I don't want a new interface , I want to keep the essential terminal and I want this assistant to work on the background and be a layer between the essential terminal and the user

 state 1:
 if the command correctly executed without errors then don't do anything

 state 2:
 trigger: the command wrongly executed, have error, or the user started the commmand with "?"
 action:
   - the agent should understand what the user wants and create a ex_bash_script
   - show ex_bash_script to the user in gray color
   - and a question "Should I execute? [Shift-Enter]" in a red color
   - if the user accept, chmod+x and excute
 more actions:
   - the bash script should be saved at /home/$USER/.llmterminal/{title}_{datatime}.sh (commenting inside this the title / description / and the user prompt)
   - and when this state happens you should save the user question with the bash script with a short description of this script do in a file

 the user will save the API_KEYS in a .env file , also here the user will decide which model to use and if it will user groq or ollama

for now, only give me the python code
